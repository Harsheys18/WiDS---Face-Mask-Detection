{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Backpropagation using XOR Dataset\n",
    "\n",
    "In this assignment, you will implement a simple feedforward neural network from scratch using only NumPy.\n",
    "\n",
    "So, we wont be using any inbuilt functions for making a neural network and we gonna use one which is made on our own.\n",
    "\n",
    "Your task is to complete the missing sections marked as \"TODO\" to create, train, and validate the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XOR Dataset -- It is XOR truth table inputs and corresponding outputs\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])  # Inputs\n",
    "y = np.array([[0], [1], [1], [0]])  # Expected outputs (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize parameters, weights and biases for a 2-layer neural network. And we here gonna use sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "\n",
    "# Random initialization of weights and biases\n",
    "W1 = np.random.randn(input_size, hidden_size)  # Weights for input to hidden layer\n",
    "b1 = np.random.randn(1, hidden_size)           # Biases for hidden layer\n",
    "W2 = np.random.randn(hidden_size, output_size)  # Weights for hidden to output layer\n",
    "b2 = np.random.randn(1, output_size)           # Biases for output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function\n",
    "\n",
    "\"\"\"Sigmoid activation function.\"\"\"\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 2-layer neural network with back propagation\n",
    "# TODO: Function for Forward Propagation\n",
    "def forward_propagation(X):\n",
    "    \"\"\"\n",
    "    Perform forward propagation to calculate the output of the network.\n",
    "\n",
    "    Returns:\n",
    "    - z1, a1: Linear and activation outputs of the hidden layer\n",
    "    - z2, a2: Linear and activation outputs of the output layer\n",
    "    \"\"\"\n",
    "    global z1, a1, z2, a2 \n",
    "    \n",
    "    return a2\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# TODO: Function for Back Propagation\n",
    "def backward_propagation(X, y, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    Perform backpropagation and update weights and biases.\n",
    "\n",
    "    Arguments:\n",
    "    - X: Input data\n",
    "    - y: True labels\n",
    "    - learning_rate: Learning rate for gradient descent\n",
    "    \"\"\"\n",
    "    global W1, b1, W2, b2\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Training the model\n",
    "# Print loss at every 1000th epoch\n",
    "epochs = 10000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "print(\"\\nValidation:\")\n",
    "print(\"Inputs:\\n\", X)\n",
    "print(\"Predicted Outputs:\\n\", np.round(output))  # Round predictions to 0 or 1\n",
    "print(\"Expected Outputs:\\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Draw a plot showing Predicted Outputs and Expected Outputs vs Inputs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
