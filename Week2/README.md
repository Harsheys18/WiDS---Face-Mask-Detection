# Weekly Focus: Introduction to Neural Networks

This week, we will dive into the basics of Neural Networks, learning how they function, how to train them, their utility in Deep Learning, various types of neural networks, Back Propagation, and Activation Functions.

**Complete Playlist**: [Simplilearn Neural Network Tutorials](https://www.simplilearn.com/tutorials/deep-learning-tutorial/neural-network)

---

## Roadmap

### Step 1: What is a Neural Network and the Types of Neural Networks

Begin by understanding how Neural Networks work and why they are essential in Deep Learning and Machine Learning.

#### Resources for Step 1:
- **Article**: [Simple Introduction to Neural Networks - Towards Data Science](https://towardsdatascience.com/simple-introduction-to-neural-networks-ac1d7c3d7a2c)
- **YouTube Playlist**: [3Blue1Brown Neural Networks Series](https://youtu.be/aircAruvnKk?si=Mz2aWN7Hbw1tAjs9)

---

### Step 2: Writing a Basic Neural Network

Practice creating a basic Neural Network. The example focuses on differentiating between cats and dogs. Most functions will be from libraries (black-box functions), but ensure you understand the underlying mechanisms.

#### Resources for Step 2:
- **Official Documentation**: [Image Classification from Scratch - Keras](https://keras.io/examples/vision/image_classification_from_scratch/)
- **YouTube Tutorial**: [Cats vs Dogs Classification - Python](https://youtu.be/J1jhfAw5Uvo?si=fmx2DQ-LWEPulgA_)

---

### Step 3: Delving Deeper into Neural Network Concepts

This step focuses on deeper concepts like Activation Functions, Backpropagation and their implementation.

1. **Activation Functions**:
   - Understand the role of ReLU, Sigmoid, Tanh, and Softmax in controlling neuron outputs.
   - Explore how activation functions impact training and convergence.

2. **Backpropagation**:
   - Learn the chain rule of differentiation and how it is used in Neural Network training.
   - Understand gradient flow and the importance of weight updates in minimizing loss.

3. **Practical Implementation**:
   - Build small models to experiment with different Activation Functions.
   - Manually implement Backpropagation using basic Python libraries like NumPy.

#### Resources for Step 3:
- **Blog**: [Understanding Activation Functions](https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/)
- **YouTube**: [Backpropagation Explained - 3Blue1Brown](https://youtu.be/Ilg3gGewQ5U)

---

## Assignments

### Assignment 1: `cat_and_dog_classifier.ipynb`

Train a simple Neural Network to classify images as either "cat" or "dog". 

---

### Assignment 2: `activation_functions_analysis.ipynb`

Explore the role of activation functions in Neural Networks by analyzing their impact on model performance. We here use a data set of MNIST digits. Train multiple models and compare the accuracy, loss, speed between them.

---

### Assignment 3: `backpropagation_simulation.ipynb`

Understand Backpropagation by implementing a Neural Network from scratch without using libraries like TensorFlow or PyTorch.

---

**Note**: Focus on understanding the fundamentals while completing these assignments. By the end of the week, you will have a solid foundation in Neural Networks and their implementation. Happy coding! ðŸš€
