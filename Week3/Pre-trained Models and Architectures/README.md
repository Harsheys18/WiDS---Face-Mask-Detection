# Pre-trained Models and Architectures

Pre-trained Models and Architectures refer to machine learning models that have been previously trained on large datasets and can be reused for similar tasks. These models, such as VGG16, ResNet, and BERT, capture rich feature representations, reducing the need for extensive training on new tasks. They are widely used for transfer learning, enabling quick adaptation to specific problems like image classification, natural language processing, or object detection.

## Resources

1. [Introduction](https://youtu.be/0MVXteg7TB4?si=8vuL6T_atEWDq1VW)
1. VGG16 [Overview](https://youtu.be/YcmNIOyfdZQ?si=nqDZbsILeGkKDkDV)
1. [VGG](https://youtu.be/YcmNIOyfdZQ?si=nqDZbsILeGkKDkDV)
1. [ResNet](https://youtu.be/o_3mboe1jYI?si=HAtCFDWjdyNoLENW)
1. CNN Architectures(AlexNet, VGGNet, Inception ResNet)[ Lecture](https://youtu.be/CNNnzl8HIIU?si=UTH0Ff9tnT4parVz)
