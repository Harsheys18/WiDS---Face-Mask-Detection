{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 3**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4kESsOo4IUhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-tuning a Pretrained ResNet Model for Image Classification"
      ],
      "metadata": {
        "id": "deWESXcqELuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "HBkG5ZRUJB_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the transformations for training and testing\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels (RGB)\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels (RGB)\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])"
      ],
      "metadata": {
        "id": "FXXZ9uIlJB7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<style>\n",
        "blue {\n",
        "  color: skyblue;\n",
        "}\n",
        "\n",
        "red {\n",
        "  color: red;\n",
        "}\n",
        "\n",
        "green {\n",
        "  color: lightgreen;\n",
        "}\n",
        "</style>\n",
        "\n",
        "1) This code outlines loading the <blue>**Cifar-10**</blue> dataset for <green>**image classification**</green>.\n",
        "2) The <blue>**train_loader**</blue> and <blue>**test_loader**</blue> are used to load the datasets in batches of 32, with shuffling applied only to the training set.\n",
        "\n",
        "Note: The placeholders **\"None\"** need to be replaced with the correct dataset-loading code."
      ],
      "metadata": {
        "id": "l7gK-ROOOhcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Use Cifar-10 dataset, you can download and load it through torchvision.datasets.ImageFolder\n",
        "train_dataset = None  # Replace None with code to load the dataset with training transformations defined above\n",
        "test_dataset = None  # Replace None with code to load the dataset with test transformations defined above\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "OfNQGf5pJB5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Replace None with correct code for loading a pretrained Resnet-18 model\n",
        "model = None\n",
        "\n",
        "# Freeze the model weights except for the final layer\n",
        "for param in model.parameters():\n",
        "    # TODO: Freeze the model weights\n",
        "    param.requires_grad = None\n",
        "\n",
        "# Modify the final fully connected layer\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)  # 10 classes in Cifar-10"
      ],
      "metadata": {
        "id": "ReKw2eBrJB3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Replace None with correct code to send model to device\n",
        "model = None\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# TODO: Use a suitable loss criterion and optimizer with learning rate 0.001\n",
        "criterion = None\n",
        "optimizer = None"
      ],
      "metadata": {
        "id": "klvVyDfFJB1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the model\n",
        "def train_model(model, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and testing phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluation mode\n",
        "                dataloader = test_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data\n",
        "            for inputs, labels in dataloader:\n",
        "                # TODO: Move images and labels to the device\n",
        "                images = None  # Replace None with the correct code\n",
        "                labels = None\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # TODO: Forward Pass\n",
        "                    outputs = None\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = None # Replace None with the correct code to find error between labels and outputs\n",
        "\n",
        "                    # Backward + optimize only in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Fine-tune the model\n",
        "fine_tuned_model = train_model(model, criterion, optimizer, num_epochs=5)"
      ],
      "metadata": {
        "id": "PLy1_IxHJBy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the model before and after fine-tuning\n",
        "# Function to visualize images and their predictions\n",
        "def visualize_predictions(model, dataloader, num_images=2):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            # TODO: Move images to the device\n",
        "            inputs = None\n",
        "\n",
        "            # TODO: Forward Pass = Get Predictions\n",
        "            outputs = None\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for i in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'Predicted: {preds[i].item()}')\n",
        "                img = inputs.cpu().data[i]\n",
        "                img = img.permute(1, 2, 0).numpy()  # Convert from Tensor format\n",
        "                img = np.clip(img, 0, 1)  # Clip the values for display\n",
        "                ax.imshow(img)\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    return\n",
        "\n",
        "# Function to denormalize the image for visualization\n",
        "def denormalize(image_tensor):\n",
        "    # Means and stds used for normalization\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = image_tensor.permute(1, 2, 0).numpy()  # Convert tensor to HWC\n",
        "    image = std * image + mean  # Denormalize\n",
        "    image = np.clip(image, 0, 1)  # Clip values to be in [0, 1] range\n",
        "    return image\n",
        "\n",
        "\n",
        "def make_map_classes(path):\n",
        "    classes_dir = os.listdir(path)\n",
        "    classes_dir.sort()\n",
        "    classes_dict = {}\n",
        "    for c in classes_dir:\n",
        "        index = int(c[:3])\n",
        "        name = c[4:]\n",
        "        classes_dict[index] = name\n",
        "\n",
        "    return classes_dict"
      ],
      "metadata": {
        "id": "0GigVXjcJBwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compare predictions of non-finetuned and finetuned models\n",
        "def compare_predictions(pretrained_model, finetuned_model, dataloader, path_dir, num_images=5):\n",
        "    pretrained_model.eval()\n",
        "    finetuned_model.eval()\n",
        "\n",
        "    images_shown = 0\n",
        "    classes_dict = make_map_classes(path_dir)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            # TODO: Move inputs to device\n",
        "            inputs = None\n",
        "\n",
        "            # Predictions from pre-trained model (without fine-tuning)\n",
        "            # TODO: Calculate outputs using forward pass of pretrained model\n",
        "            pre_outputs = None\n",
        "            _, pre_preds = torch.max(pre_outputs, 1)\n",
        "\n",
        "            # Predictions from fine-tuned model\n",
        "            # TODO: Calculate the outputs using the gforward pass of the finetuned model\n",
        "            fin_outputs = None\n",
        "            _, fin_preds = torch.max(fin_outputs, 1)\n",
        "\n",
        "            for i in range(inputs.size()[0]):\n",
        "                if images_shown == num_images:\n",
        "                    return  # Stop after showing num_images\n",
        "                images_shown += 1\n",
        "\n",
        "                img = denormalize(inputs.cpu().data[i])\n",
        "\n",
        "                plt.figure(figsize=(10, 4))\n",
        "\n",
        "                # Show pre-trained model's prediction\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.imshow(img)\n",
        "                plt.title(f'Pre-trained Prediction: {pre_preds[i].item()} : {classes_dict[pre_preds[i].item()]}')\n",
        "                plt.axis('off')\n",
        "\n",
        "                # Show fine-tuned model's prediction\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.imshow(img)\n",
        "                plt.title(f'Fine-tuned Prediction: {fin_preds[i].item()} : {classes_dict[fin_preds[i].item()+1]}')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.show()"
      ],
      "metadata": {
        "id": "Fyr46qoDJBtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and visualize predictions\n",
        "print(\"Comparing predictions of pre-trained and fine-tuned models on example images...\")\n",
        "\n",
        "# Ensure both models have the same structure (so, freeze layers for pretrained_model)\n",
        "pretrained_model = models.resnet18(pretrained=True)\n",
        "pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, 10)\n",
        "pretrained_model = pretrained_model.to(device)\n",
        "\n",
        "# Compare predictions using a couple of test images\n",
        "# TODO: Fill in the path of the 256_ObjectCategories directory in the path variable below.\n",
        "path_to256_ObjectCategories_dir = None\n",
        "compare_predictions(pretrained_model, fine_tuned_model, test_loader, path_to256_ObjectCategories_dir ,num_images=10)\n"
      ],
      "metadata": {
        "id": "QEOf8HQ7JBqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}